{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade langchain openai  -q\n!pip install -q accelerate -U\n!pip install transformers==4.31.0 -q\n!pip install -q bitsandbytes==0.40.2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-14T06:07:47.302650Z","iopub.execute_input":"2024-04-14T06:07:47.303143Z","iopub.status.idle":"2024-04-14T06:08:40.148452Z","shell.execute_reply.started":"2024-04-14T06:07:47.303105Z","shell.execute_reply":"2024-04-14T06:08:40.147232Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"This Notebook is inspired from course  LangChain for LLM Application Development. They has done all these things with OPENAI API. As they are very few resources for models on hugging face, I tried similar things on Llama2 13b chat model which is loaded from hugging Face","metadata":{}},{"cell_type":"markdown","source":"# Loading Model(Llama2 13b chat model from huggingface)","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import cuda, bfloat16\nimport transformers\n\nmodel_id = 'meta-llama/Llama-2-13b-chat-hf'\n\ndevice = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n\n# set quantization configuration to load large model with less GPU memory\n# this requires the `bitsandbytes` library\nbnb_config = transformers.BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type='nf4',\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=bfloat16\n)\n\n# begin initializing HF items, need auth token for these\nhf_auth = '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'\nmodel_config = transformers.AutoConfig.from_pretrained(\n    model_id,\n    use_auth_token=hf_auth\n)\n\nmodel = transformers.AutoModelForCausalLM.from_pretrained(\n    model_id,\n    trust_remote_code=True,\n    config=model_config,\n    quantization_config=bnb_config,\n    device_map= {\"\": 0},\n    use_auth_token=hf_auth\n)\nmodel.eval()\nprint(f\"Model loaded on {device}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-14T06:09:35.108840Z","iopub.execute_input":"2024-04-14T06:09:35.109233Z","iopub.status.idle":"2024-04-14T06:13:45.129280Z","shell.execute_reply.started":"2024-04-14T06:09:35.109192Z","shell.execute_reply":"2024-04-14T06:13:45.128176Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/587 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47312222ad944075b3efebbb40d4f5bf"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/33.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c78dd66f25ac42f9bc37ac6809cace50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4b5d4b3a6f146a882d195f97842182a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97a83a583cc4437d8cceffb81aae5a60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/9.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b2154e65bac466d86e55b1bf33ac1f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/6.18G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0b91a7688ea4e84a50d19184729b5a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fccc6067fd6546faab7358350582346a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32bd990acaa84151bd84620c10efa30f"}},"metadata":{}},{"name":"stdout","text":"Model loaded on cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = transformers.AutoTokenizer.from_pretrained(\n    model_id,\n    use_auth_token=hf_auth\n)\ngenerate_text = transformers.pipeline(\n    model=model, tokenizer=tokenizer,\n    return_full_text=True,  # langchain expects the full text\n    task='text-generation',\n    # we pass model parameters here too\n    temperature=0.1,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n    max_new_tokens=512,# max number of tokens to generate in the output\n    repetition_penalty=1.1  # without this output begins repeation\n\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T06:14:22.539841Z","iopub.execute_input":"2024-04-14T06:14:22.540943Z","iopub.status.idle":"2024-04-14T06:14:35.419929Z","shell.execute_reply.started":"2024-04-14T06:14:22.540908Z","shell.execute_reply":"2024-04-14T06:14:35.419036Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5ca5d19fd1346d09eb795d8ac7b803d"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21e94ecc178742bb9699362d1d3077a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c92574da1fc04fd887fddf70e8cebb56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f1d3e9dd1354a1aaef475b06f81f322"}},"metadata":{}},{"name":"stderr","text":"2024-04-14 06:14:24.694356: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-14 06:14:24.694476: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-14 06:14:24.785560: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nXformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\npip install xformers.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Passing the pipeline created to langchain.**","metadata":{}},{"cell_type":"code","source":"from langchain.llms import HuggingFacePipeline\n\nllm = HuggingFacePipeline(pipeline=generate_text) ","metadata":{"execution":{"iopub.status.busy":"2024-04-14T06:14:35.421588Z","iopub.execute_input":"2024-04-14T06:14:35.422286Z","iopub.status.idle":"2024-04-14T06:14:35.830949Z","shell.execute_reply.started":"2024-04-14T06:14:35.422202Z","shell.execute_reply":"2024-04-14T06:14:35.830118Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# **Prompt Template**","metadata":{}},{"cell_type":"code","source":"prompt = \"\"\"Translate the text \\\nthat is delimited by triple backticks \\\ninto a style that is {style}. \\\ntext: ```{text}```\n\"\"\"\n\n# For LLama models prompting will be different from openai models.\n# Every instruction should have [INST][/INST] tags\n# system prompts can be forwarded between <<SYS>> <</SYS>>\n\ntemplate_string=f\"<s>[INST] <<SYS>>\\nDon't generate input again\\n<</SYS>>\\n\\n{prompt} [/INST]</s>\"","metadata":{"execution":{"iopub.status.busy":"2024-04-14T06:15:01.922951Z","iopub.execute_input":"2024-04-14T06:15:01.923375Z","iopub.status.idle":"2024-04-14T06:15:01.928358Z","shell.execute_reply.started":"2024-04-14T06:15:01.923346Z","shell.execute_reply":"2024-04-14T06:15:01.927196Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from langchain.prompts import ChatPromptTemplate\n\nprompt_template = ChatPromptTemplate.from_template(template_string)\n\nprompt_template.messages[0].prompt","metadata":{"execution":{"iopub.status.busy":"2024-04-14T06:15:03.881331Z","iopub.execute_input":"2024-04-14T06:15:03.882642Z","iopub.status.idle":"2024-04-14T06:15:04.055569Z","shell.execute_reply.started":"2024-04-14T06:15:03.882595Z","shell.execute_reply":"2024-04-14T06:15:04.054471Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"PromptTemplate(input_variables=['style', 'text'], template=\"<s>[INST] <<SYS>>\\nDon't generate input again\\n<</SYS>>\\n\\nTranslate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n [/INST]</s>\")"},"metadata":{}}]},{"cell_type":"code","source":"customer_style = \"\"\"American English \\\nin a calm and respectful tone\n\"\"\"\n\ncustomer_email = \"\"\"\nArrr, I be fuming that me blender lid \\\nflew off and splattered me kitchen walls \\\nwith smoothie! And to make matters worse, \\\nthe warranty don't cover the cost of \\\ncleaning up me kitchen. I need yer help \\\nright now, matey!\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-14T06:15:09.675023Z","iopub.execute_input":"2024-04-14T06:15:09.675716Z","iopub.status.idle":"2024-04-14T06:15:09.680148Z","shell.execute_reply.started":"2024-04-14T06:15:09.675678Z","shell.execute_reply":"2024-04-14T06:15:09.679236Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"**For the style we're direct prompt template can't be passed to the model. We will have to send the content**","metadata":{}},{"cell_type":"code","source":"customer_messages = prompt_template.format_messages(\n                    style=customer_style,\n                    text=customer_email)\n\nprint(customer_messages[0].content)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T06:15:12.536428Z","iopub.execute_input":"2024-04-14T06:15:12.537435Z","iopub.status.idle":"2024-04-14T06:15:12.543473Z","shell.execute_reply.started":"2024-04-14T06:15:12.537395Z","shell.execute_reply":"2024-04-14T06:15:12.542497Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"<s>[INST] <<SYS>>\nDon't generate input again\n<</SYS>>\n\nTranslate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone\n. text: ```\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n```\n [/INST]</s>\n","output_type":"stream"}]},{"cell_type":"code","source":"customer_response = llm(customer_messages[0].content)\n\ncustomer_review = \"\"\"\\\nThis leaf blower is pretty amazing.  It has four settings:\\\ncandle blower, gentle breeze, windy city, and tornado. \\\nIt arrived in two days, just in time for my wife's \\\nanniversary present. \\\nI think my wife liked it so much she was speechless. \\\nSo far I've been the only one using it, and I've been \\\nusing it every other morning to clear the leaves on our lawn. \\\nIt's slightly more expensive than the other leaf blowers \\\nout there, but I think it's worth it for the extra features.\n\"\"\"\n\nreview_template = \"\"\"\\\nFor the following text, extract the following information:\n\ngift: Was the item purchased as a gift for someone else? \\\nAnswer True if yes, False if not or unknown.\n\ndelivery_days: How many days did it take for the product \\\nto arrive? If this information is not found, output -1.\n\nprice_value: Extract any sentences about the value or price,\\\nand output them as a comma separated Python list.\n\nFormat the output as JSON with the following keys:\ngift\ndelivery_days\nprice_value\n\ntext: {text}\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-14T06:15:16.743444Z","iopub.execute_input":"2024-04-14T06:15:16.744234Z","iopub.status.idle":"2024-04-14T06:15:41.420886Z","shell.execute_reply.started":"2024-04-14T06:15:16.744184Z","shell.execute_reply":"2024-04-14T06:15:41.419756Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n  warn_deprecated(\n","output_type":"stream"}]},{"cell_type":"code","source":"from langchain.prompts import ChatPromptTemplate\n\nprompt_template = ChatPromptTemplate.from_template(review_template)\nprint(prompt_template)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T06:15:46.587862Z","iopub.execute_input":"2024-04-14T06:15:46.588706Z","iopub.status.idle":"2024-04-14T06:15:46.594466Z","shell.execute_reply.started":"2024-04-14T06:15:46.588666Z","shell.execute_reply":"2024-04-14T06:15:46.593471Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"input_variables=['text'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\nFormat the output as JSON with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: {text}\\n'))]\n","output_type":"stream"}]},{"cell_type":"code","source":"messages = prompt_template.format_messages(text=customer_review)\nresponse = llm(messages[0].content)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T06:16:04.125150Z","iopub.execute_input":"2024-04-14T06:16:04.126117Z","iopub.status.idle":"2024-04-14T06:16:12.605380Z","shell.execute_reply.started":"2024-04-14T06:16:04.126084Z","shell.execute_reply":"2024-04-14T06:16:12.604363Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"For the following text, extract the following information:\n\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\n\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n\nFormat the output as JSON with the following keys:\ngift\ndelivery_days\nprice_value\n\ntext: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n\noutput:\n{\n\"gift\":True,\n\"delivery_days\":2,\n\"price_value\":[\"pretty amazing\", \"slightly more expensive\"]\n}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Output Parsing**","metadata":{}},{"cell_type":"code","source":"customer_review = \"\"\"\\\nThis leaf blower is pretty amazing.  It has four settings:\\\ncandle blower, gentle breeze, windy city, and tornado. \\\nIt arrived in two days, just in time for my wife's \\\nanniversary present. \\\nI think my wife liked it so much she was speechless. \\\nSo far I've been the only one using it, and I've been \\\nusing it every other morning to clear the leaves on our lawn. \\\nIt's slightly more expensive than the other leaf blowers \\\nout there, but I think it's worth it for the extra features.\n\"\"\"\n\nreview_template = \"\"\"\\\nFor the following text, extract the following information:\n\ngift: Was the item purchased as a gift for someone else? \\\nAnswer true if yes, false if not or unknown.\n\ndelivery_days: How many days did it take for the product \\\nto arrive? If this information is not found, output -1.\n\nprice_value: Extract any sentences about the value or price,\\\nand output them as a comma separated Python list.\n\nFormat the output as markdown JSON with the following keys and output should be followed by \"Output\":\ngift\ndelivery_days\nprice_value\n\ntext: {text}\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-14T08:31:09.899930Z","iopub.execute_input":"2024-04-14T08:31:09.900813Z","iopub.status.idle":"2024-04-14T08:31:09.906138Z","shell.execute_reply.started":"2024-04-14T08:31:09.900778Z","shell.execute_reply":"2024-04-14T08:31:09.905041Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"from langchain.prompts import ChatPromptTemplate\n\nprompt_template = ChatPromptTemplate.from_template(review_template)\nprint(prompt_template)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T08:31:12.223064Z","iopub.execute_input":"2024-04-14T08:31:12.224073Z","iopub.status.idle":"2024-04-14T08:31:12.230047Z","shell.execute_reply.started":"2024-04-14T08:31:12.224032Z","shell.execute_reply":"2024-04-14T08:31:12.228972Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"input_variables=['text'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer true if yes, false if not or unknown.\\n\\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\nFormat the output as markdown JSON with the following keys and output should be followed by \"Output\":\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: {text}\\n'))]\n","output_type":"stream"}]},{"cell_type":"code","source":"messages = prompt_template.format_messages(text=customer_review)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T08:31:14.436095Z","iopub.execute_input":"2024-04-14T08:31:14.436604Z","iopub.status.idle":"2024-04-14T08:31:14.441767Z","shell.execute_reply.started":"2024-04-14T08:31:14.436565Z","shell.execute_reply":"2024-04-14T08:31:14.440681Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"response = llm(messages[0].content)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T08:31:17.610818Z","iopub.execute_input":"2024-04-14T08:31:17.611188Z","iopub.status.idle":"2024-04-14T08:31:27.460758Z","shell.execute_reply.started":"2024-04-14T08:31:17.611159Z","shell.execute_reply":"2024-04-14T08:31:27.459724Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"For the following text, extract the following information:\n\ngift: Was the item purchased as a gift for someone else? Answer true if yes, false if not or unknown.\n\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\n\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n\nFormat the output as markdown JSON with the following keys and output should be followed by \"Output\":\ngift\ndelivery_days\nprice_value\n\ntext: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n\nOutput:\n{\n\"gift\": true,\n\"delivery_days\": 2,\n\"price_value\": [\"slightly more expensive than the other leaf blowers out there\"]\n}\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_content_after_word(input_string, word):\n    # Find the position of the word in the string\n    word_position = input_string.find(word)\n    \n    # If the word is found\n    if word_position != -1:\n        # Extract the content after the word\n        content_after_word = input_string[word_position + len(word):].strip()\n        content_after_word = \"```json\"+'\\n'+content_after_word +\"```\"\n        return content_after_word\n    else:\n        return \"Word not found in the string.\"\n    \ncontent_after_word = get_content_after_word(response,\"Output:\")","metadata":{"execution":{"iopub.status.busy":"2024-04-14T08:31:27.462729Z","iopub.execute_input":"2024-04-14T08:31:27.463418Z","iopub.status.idle":"2024-04-14T08:31:27.469336Z","shell.execute_reply.started":"2024-04-14T08:31:27.463386Z","shell.execute_reply":"2024-04-14T08:31:27.468161Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"print(content_after_word)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T08:31:27.521501Z","iopub.execute_input":"2024-04-14T08:31:27.521760Z","iopub.status.idle":"2024-04-14T08:31:27.526581Z","shell.execute_reply.started":"2024-04-14T08:31:27.521738Z","shell.execute_reply":"2024-04-14T08:31:27.525528Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"```json\n{\n\"gift\": true,\n\"delivery_days\": 2,\n\"price_value\": [\"slightly more expensive than the other leaf blowers out there\"]\n}```\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Trying out Langchain Output Parsers**","metadata":{}},{"cell_type":"code","source":"from langchain.output_parsers import ResponseSchema\nfrom langchain.output_parsers import StructuredOutputParser\n\ngift_schema = ResponseSchema(name=\"gift\",\n                             description=\"Was the item purchased\\\n                             as a gift for someone else? \\\n                             Answer True if yes,\\\n                             False if not or unknown.\")\ndelivery_days_schema = ResponseSchema(name=\"delivery_days\",\n                                      description=\"How many days\\\n                                      did it take for the product\\\n                                      to arrive? If this \\\n                                      information is not found,\\\n                                      output -1.\")\nprice_value_schema = ResponseSchema(name=\"price_value\",\n                                    description=\"Extract any\\\n                                    sentences about the value or \\\n                                    price, and output them as a \\\n                                    comma separated Python list.\")\n\nresponse_schemas = [gift_schema, \n                    delivery_days_schema,\n                    price_value_schema]","metadata":{"execution":{"iopub.status.busy":"2024-04-14T06:37:18.938620Z","iopub.execute_input":"2024-04-14T06:37:18.939024Z","iopub.status.idle":"2024-04-14T06:37:18.948183Z","shell.execute_reply.started":"2024-04-14T06:37:18.938993Z","shell.execute_reply":"2024-04-14T06:37:18.947287Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"output_parser = StructuredOutputParser.from_response_schemas(response_schemas)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T06:37:35.034666Z","iopub.execute_input":"2024-04-14T06:37:35.035375Z","iopub.status.idle":"2024-04-14T06:37:35.040137Z","shell.execute_reply.started":"2024-04-14T06:37:35.035338Z","shell.execute_reply":"2024-04-14T06:37:35.039022Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"format_instructions = output_parser.get_format_instructions()\n\nprint(format_instructions)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T06:38:03.875879Z","iopub.execute_input":"2024-04-14T06:38:03.876271Z","iopub.status.idle":"2024-04-14T06:38:03.881738Z","shell.execute_reply.started":"2024-04-14T06:38:03.876235Z","shell.execute_reply":"2024-04-14T06:38:03.880767Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n\n```json\n{\n\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n}\n```\n","output_type":"stream"}]},{"cell_type":"code","source":"review_template_2 = \"\"\"\\\nFor the following text, extract the following information:\n\ngift: Was the item purchased as a gift for someone else? \\\nAnswer True if yes, False if not or unknown.\n\ndelivery_days: How many days did it take for the product\\\nto arrive? If this information is not found, output -1.\n\nprice_value: Extract any sentences about the value or price,\\\nand output them as a comma separated Python list.\n\ntext: {text}\n\nGiven below is the format which the extracted data should be generated\n{format_instructions}\n\"\"\"\n\nprompt = ChatPromptTemplate.from_template(template=review_template_2)\n\nmessages = prompt.format_messages(text=customer_review, \n                                format_instructions=format_instructions)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T06:46:57.895662Z","iopub.execute_input":"2024-04-14T06:46:57.896592Z","iopub.status.idle":"2024-04-14T06:46:57.902424Z","shell.execute_reply.started":"2024-04-14T06:46:57.896559Z","shell.execute_reply":"2024-04-14T06:46:57.901278Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"print(messages[0].content)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T06:47:01.015175Z","iopub.execute_input":"2024-04-14T06:47:01.016061Z","iopub.status.idle":"2024-04-14T06:47:01.020982Z","shell.execute_reply.started":"2024-04-14T06:47:01.016029Z","shell.execute_reply":"2024-04-14T06:47:01.019797Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"For the following text, extract the following information:\n\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n\ndelivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\n\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n\ntext: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n\n\nGiven below is the format which the extracted data should be generated\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n\n```json\n{\n\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n}\n```\n\n","output_type":"stream"}]},{"cell_type":"code","source":"response = llm(messages[0].content)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T06:47:08.928324Z","iopub.execute_input":"2024-04-14T06:47:08.928729Z","iopub.status.idle":"2024-04-14T06:47:16.541776Z","shell.execute_reply.started":"2024-04-14T06:47:08.928697Z","shell.execute_reply":"2024-04-14T06:47:16.540672Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"For the following text, extract the following information:\n\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n\ndelivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\n\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n\ntext: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n\n\nGiven below is the format which the extracted data should be generated\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n\n```json\n{\n\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n}\n```\n\nPlease help me with the code to extract the required information from the given text.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Not sure about the reason but as you can see langchain output parsers are not working for Llama2 13-b chat model, atleast for this** **usecase. \nIdeal way would be parsing it on our own as we have done previously**","metadata":{}},{"cell_type":"markdown","source":"**Parser will check the keys we have given in responseSchema and validate whether our output is having those or not.**","metadata":{}},{"cell_type":"code","source":"# we are taking \"content_after_word\" which we extracted before.\noutput_dict = output_parser.parse(content_after_word)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T08:31:34.653752Z","iopub.execute_input":"2024-04-14T08:31:34.654480Z","iopub.status.idle":"2024-04-14T08:31:34.660185Z","shell.execute_reply.started":"2024-04-14T08:31:34.654445Z","shell.execute_reply":"2024-04-14T08:31:34.658976Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"print(type(output_dict))\nprint(output_dict)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T08:32:06.987848Z","iopub.execute_input":"2024-04-14T08:32:06.988316Z","iopub.status.idle":"2024-04-14T08:32:06.993406Z","shell.execute_reply.started":"2024-04-14T08:32:06.988282Z","shell.execute_reply":"2024-04-14T08:32:06.992425Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"<class 'dict'>\n{'gift': True, 'delivery_days': 2, 'price_value': ['slightly more expensive than the other leaf blowers out there']}\n","output_type":"stream"}]}]}